#!/usr/bin/env python3
"""
Generate Rust reference data files from JSON sources.

This script generates:
- src/reference/dxcc.rs from resources/dxcc_entities.json
- src/reference/states.rs from resources/us_states.json and resources/canadian_provinces.json

NOTE: src/reference/prefixes.rs is NOT generated by this script.
The prefix rules require manual curation because:
1. Multiple entities can share the same prefix (e.g., HK0 for both Malpelo and San Andres)
2. Disambiguation requires suffix patterns (e.g., HK0M for Malpelo)
3. The dxcc_entities.json Prefixes field lacks this level of detail

When updating prefix rules, edit prefixes.rs directly and run the tests.

Usage:
    python scripts/generate_reference.py

Or from src-tauri:
    python ../scripts/generate_reference.py

The generated files should be committed to the repository.
DO NOT manually edit dxcc.rs or states.rs - edit the JSON sources instead.
"""

import json
import os
from datetime import datetime, timezone
from pathlib import Path

# Determine paths relative to this script or src-tauri
def get_project_paths():
    """Find project paths whether run from project root or src-tauri."""
    script_dir = Path(__file__).parent.resolve()
    
    # Try project root first (scripts/ is at root level)
    project_root = script_dir.parent
    src_tauri = project_root / "src-tauri"
    
    if src_tauri.exists():
        return project_root, src_tauri
    
    # Maybe we're inside src-tauri already
    if (script_dir / "src" / "reference").exists():
        return script_dir.parent, script_dir
    
    raise RuntimeError("Cannot determine project paths. Run from project root or src-tauri.")

PROJECT_ROOT, SRC_TAURI = get_project_paths()
RESOURCES_DIR = SRC_TAURI / "resources"
REFERENCE_DIR = SRC_TAURI / "src" / "reference"

def get_timestamp():
    """Return ISO 8601 timestamp in UTC."""
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

def load_json(filename):
    """Load a JSON file from resources directory."""
    filepath = RESOURCES_DIR / filename
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def write_rust_file(filename, content):
    """Write content to a Rust file in the reference directory."""
    filepath = REFERENCE_DIR / filename
    with open(filepath, 'w', encoding='utf-8', newline='\n') as f:
        f.write(content)
    print(f"Generated: {filepath}")

# =============================================================================
# DXCC ENTITY GENERATION
# =============================================================================

def generate_dxcc_rs():
    """Generate dxcc.rs from dxcc_entities.json."""
    entities = load_json("dxcc_entities.json")
    timestamp = get_timestamp()
    
    # Count current vs deleted
    current_count = sum(1 for e in entities if not e.get("Deleted", False))
    deleted_count = sum(1 for e in entities if e.get("Deleted", False))
    total_count = len(entities)
    
    lines = [
        "// DXCC Entity List - Current and Deleted Entities",
        "// Source: ARRL DXCC List (https://www.arrl.org/files/file/DXCC/Current_Deleted.txt)",
        f"// Generated: {timestamp} from dxcc_entities.json",
        "//",
        "// This is the authoritative list of DXCC entities as defined by ARRL.",
        f"// Total: {total_count} entities ({current_count} current + {deleted_count} deleted)",
        "//",
        "// Entity IDs use ARRL's 3-digit zero-padded string format (e.g., \"001\" for Canada)",
        "//",
        "// DO NOT MANUALLY EDIT - regenerate using: python scripts/generate_reference.py",
        "//",
        "#![allow(dead_code)]",
        "",
        "use serde::{Deserialize, Serialize};",
        "",
        "#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]",
        "pub struct DxccEntity {",
        "    pub entity_id: &'static str,  // ARRL 3-digit format: \"001\", \"291\", etc.",
        "    pub name: &'static str,",
        "    pub continent: &'static str,",
        "    pub cq_zones: &'static [u8],",
        "    pub itu_zones: &'static [u8],",
        "    pub deleted: bool,",
        "}",
        "",
        "/// DXCC entities list from official ARRL data",
        "pub const DXCC_ENTITIES: &[DxccEntity] = &[",
    ]
    
    for entity in entities:
        # Use ARRL's 3-digit zero-padded string format
        entity_id = entity["EntityId"]  # Already "001" format in JSON
        name = entity["Name"].replace('"', '\\"')
        continent = entity.get("Continent", "")
        deleted = "true" if entity.get("Deleted", False) else "false"
        
        # Handle CQ zones (can be null, int, or array)
        cq_zones = entity.get("CqZones")
        if cq_zones is None:
            cq_str = "&[]"
        elif isinstance(cq_zones, list):
            cq_str = "&[" + ", ".join(str(z) for z in cq_zones) + "]"
        else:
            cq_str = f"&[{cq_zones}]"
        
        # Handle ITU zones (can be null, int, or array)
        itu_zones = entity.get("ItuZones")
        if itu_zones is None:
            itu_str = "&[]"
        elif isinstance(itu_zones, list):
            itu_str = "&[" + ", ".join(str(z) for z in itu_zones) + "]"
        else:
            itu_str = f"&[{itu_zones}]"
        
        lines.append(
            f'    DxccEntity {{ entity_id: "{entity_id}", name: "{name}", '
            f'continent: "{continent}", cq_zones: {cq_str}, itu_zones: {itu_str}, '
            f'deleted: {deleted} }},'
        )
    
    lines.append("];")
    lines.append("")
    
    # Add helper functions
    lines.extend([
        "/// Get entity by ID (ARRL 3-digit format: \"001\", \"291\", etc.)",
        "pub fn get_entity_by_id(entity_id: &str) -> Option<&'static DxccEntity> {",
        "    DXCC_ENTITIES.iter().find(|e| e.entity_id == entity_id)",
        "}",
        "",
        "/// Get entity by name (case-insensitive)",
        "pub fn get_entity_by_name(name: &str) -> Option<&'static DxccEntity> {",
        "    let name_lower = name.to_lowercase();",
        "    DXCC_ENTITIES.iter().find(|e| e.name.to_lowercase() == name_lower)",
        "}",
        "",
        "/// Get all current (non-deleted) entities",
        "pub fn get_current_entities() -> Vec<&'static DxccEntity> {",
        "    DXCC_ENTITIES.iter().filter(|e| !e.deleted).collect()",
        "}",
        "",
        "/// Get count of current entities",
        "pub fn get_current_entity_count() -> usize {",
        "    DXCC_ENTITIES.iter().filter(|e| !e.deleted).count()",
        "}",
        "",
    ])
    
    write_rust_file("dxcc.rs", "\n".join(lines))
    return total_count, current_count, deleted_count

# =============================================================================
# STATES GENERATION
# =============================================================================

def generate_states_rs():
    """Generate states.rs from us_states.json and canadian_provinces.json."""
    us_data = load_json("us_states.json")
    ca_data = load_json("canadian_provinces.json")
    timestamp = get_timestamp()
    
    us_states = us_data["states"]
    ca_provinces = ca_data["provinces"]
    ca_territories = ca_data["territories"]
    
    lines = [
        "// US States and Canadian Provinces for award tracking",
        "// Source: USPS (US), Canada Post (CA), ARRL WAS/RAC rules",
        f"// Generated: {timestamp} from us_states.json and canadian_provinces.json",
        "//",
        "// DO NOT MANUALLY EDIT - regenerate using: python scripts/generate_reference.py",
        "//",
        "#![allow(dead_code)]",
        "",
        "// =========================================================================",
        "// US STATES (WAS Award - 50 states required)",
        "// =========================================================================",
        "",
        "/// US State information for WAS tracking",
        "#[derive(Debug, Clone)]",
        "pub struct UsState {",
        "    /// Two-letter USPS abbreviation",
        "    pub code: &'static str,",
        "    /// Full state name",
        "    pub name: &'static str,",
        "}",
        "",
        "/// All 50 US states",
        "pub const US_STATES: &[UsState] = &[",
    ]
    
    for state in us_states:
        code = state["code"]
        name = state["name"].replace('"', '\\"')
        lines.append(f'    UsState {{ code: "{code}", name: "{name}" }},')
    
    lines.append("];")
    lines.append("")
    
    # Canadian provinces
    lines.extend([
        "// =========================================================================",
        "// CANADIAN PROVINCES AND TERRITORIES",
        "// =========================================================================",
        "",
        "/// Canadian Province/Territory information for RAC award tracking",
        "#[derive(Debug, Clone)]",
        "pub struct CanadianProvince {",
        "    /// Two-letter Canada Post abbreviation",
        "    pub code: &'static str,",
        "    /// Full province/territory name",
        "    pub name: &'static str,",
        "}",
        "",
        "/// All 13 Canadian provinces and territories",
        "pub const CANADIAN_PROVINCES: &[CanadianProvince] = &[",
        "    // Provinces (10)",
    ])
    
    for prov in ca_provinces:
        code = prov["code"]
        name = prov["name"].replace('"', '\\"')
        lines.append(f'    CanadianProvince {{ code: "{code}", name: "{name}" }},')
    
    lines.append("    // Territories (3)")
    
    for terr in ca_territories:
        code = terr["code"]
        name = terr["name"].replace('"', '\\"')
        lines.append(f'    CanadianProvince {{ code: "{code}", name: "{name}" }},')
    
    lines.append("];")
    lines.append("")
    
    # Helper functions
    lines.extend([
        "/// Get US state by code",
        "pub fn get_us_state(code: &str) -> Option<&'static UsState> {",
        "    let code_upper = code.to_uppercase();",
        "    US_STATES.iter().find(|s| s.code == code_upper)",
        "}",
        "",
        "/// Get Canadian province by code",
        "pub fn get_canadian_province(code: &str) -> Option<&'static CanadianProvince> {",
        "    let code_upper = code.to_uppercase();",
        "    CANADIAN_PROVINCES.iter().find(|p| p.code == code_upper)",
        "}",
        "",
        "/// Check if a state code is a valid US state",
        "pub fn is_valid_us_state(code: &str) -> bool {",
        "    get_us_state(code).is_some()",
        "}",
        "",
        "/// Check if a code is a valid Canadian province/territory",
        "pub fn is_valid_canadian_province(code: &str) -> bool {",
        "    get_canadian_province(code).is_some()",
        "}",
        "",
        "#[cfg(test)]",
        "mod tests {",
        "    use super::*;",
        "",
        "    #[test]",
        "    fn test_us_states_count() {",
        "        assert_eq!(US_STATES.len(), 50);",
        "    }",
        "",
        "    #[test]",
        "    fn test_canadian_provinces_count() {",
        "        assert_eq!(CANADIAN_PROVINCES.len(), 13);",
        "    }",
        "",
        "    #[test]",
        "    fn test_us_state_lookup() {",
        "        assert!(get_us_state(\"MN\").is_some());",
        "        assert!(get_us_state(\"mn\").is_some()); // case insensitive",
        "        assert!(get_us_state(\"XX\").is_none());",
        "    }",
        "",
        "    #[test]",
        "    fn test_canadian_province_lookup() {",
        "        assert!(get_canadian_province(\"ON\").is_some());",
        "        assert!(get_canadian_province(\"on\").is_some()); // case insensitive",
        "        assert!(get_canadian_province(\"XX\").is_none());",
        "    }",
        "}",
        "",
    ])
    
    write_rust_file("states.rs", "\n".join(lines))
    return len(us_states), len(ca_provinces) + len(ca_territories)

# =============================================================================
# MAIN
# =============================================================================

def main():
    print("=" * 60)
    print("GoQSO Reference Data Generator")
    print("=" * 60)
    print(f"Resources: {RESOURCES_DIR}")
    print(f"Output:    {REFERENCE_DIR}")
    print()
    
    # Generate dxcc.rs
    print("Generating dxcc.rs...")
    total, current, deleted = generate_dxcc_rs()
    print(f"  → {total} entities ({current} current, {deleted} deleted)")
    print()
    
    # Generate states.rs
    print("Generating states.rs...")
    us_count, ca_count = generate_states_rs()
    print(f"  → {us_count} US states, {ca_count} Canadian provinces/territories")
    print()
    
    # Note about prefixes.rs
    print("NOTE: prefixes.rs is manually maintained (not generated)")
    print("  → Prefix disambiguation requires manual curation")
    print()
    
    print("=" * 60)
    print("Generation complete!")
    print()
    print("Next steps:")
    print("  1. Run 'cargo check' to verify compilation")
    print("  2. Run 'cargo test' to run tests")
    print("  3. Commit the generated .rs files")
    print()

if __name__ == "__main__":
    main()
